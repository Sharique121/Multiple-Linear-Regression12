{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0  165349.20       136897.80        471784.10    New York  192261.83\n",
       "1  162597.70       151377.59        443898.53  California  191792.06\n",
       "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3  144372.41       118671.85        383199.62    New York  182901.99\n",
       "4  142107.34        91391.77        366168.42     Florida  166187.94"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"50_Startups.csv\")\n",
    "data.head()\n",
    "# \"\"\" Here the data set represents lists of investments, states amount shelled out by the admins\n",
    "# on the upcoming startups and the amount which it made\n",
    "# The objective here is to understand whether it is profitable in investing \n",
    "# in a startup or not\n",
    "\n",
    "# Profit here is a dependent variable\n",
    "# Rest of the variables are indepenent variable\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R&D Spend          0\n",
       "Administration     0\n",
       "Marketing Spend    0\n",
       "State              0\n",
       "Profit             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple Linear is same as Linear Regression but with many variables\n",
    "#IN this the input variables and the output variables are continuous in nature\n",
    "#some input varibales can be discrete for these variables you need to convert the variables into dummy variables\n",
    "#by discrete we mean the variables are not continuous but can be categorical in nature\n",
    "\n",
    "X=data.iloc[:,:4].values\n",
    "#X.head()\n",
    "y=data.iloc[:, 4].values\n",
    "#pd.get_dummies(X[:,3]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.00000000e+00   0.00000000e+00   1.00000000e+00   1.65349200e+05\n",
      "    1.36897800e+05   4.71784100e+05]\n",
      " [  1.00000000e+00   0.00000000e+00   0.00000000e+00   1.62597700e+05\n",
      "    1.51377590e+05   4.43898530e+05]\n",
      " [  0.00000000e+00   1.00000000e+00   0.00000000e+00   1.53441510e+05\n",
      "    1.01145550e+05   4.07934540e+05]\n",
      " [  0.00000000e+00   0.00000000e+00   1.00000000e+00   1.44372410e+05\n",
      "    1.18671850e+05   3.83199620e+05]\n",
      " [  0.00000000e+00   1.00000000e+00   0.00000000e+00   1.42107340e+05\n",
      "    9.13917700e+04   3.66168420e+05]\n",
      " [  0.00000000e+00   0.00000000e+00   1.00000000e+00   1.31876900e+05\n",
      "    9.98147100e+04   3.62861360e+05]\n",
      " [  1.00000000e+00   0.00000000e+00   0.00000000e+00   1.34615460e+05\n",
      "    1.47198870e+05   1.27716820e+05]\n",
      " [  0.00000000e+00   1.00000000e+00   0.00000000e+00   1.30298130e+05\n",
      "    1.45530060e+05   3.23876680e+05]\n",
      " [  0.00000000e+00   0.00000000e+00   1.00000000e+00   1.20542520e+05\n",
      "    1.48718950e+05   3.11613290e+05]\n",
      " [  1.00000000e+00   0.00000000e+00   0.00000000e+00   1.23334880e+05\n",
      "    1.08679170e+05   3.04981620e+05]\n",
      " [  0.00000000e+00   1.00000000e+00   0.00000000e+00   1.01913080e+05\n",
      "    1.10594110e+05   2.29160950e+05]\n",
      " [  1.00000000e+00   0.00000000e+00   0.00000000e+00   1.00671960e+05\n",
      "    9.17906100e+04   2.49744550e+05]\n",
      " [  0.00000000e+00   1.00000000e+00   0.00000000e+00   9.38637500e+04\n",
      "    1.27320380e+05   2.49839440e+05]\n",
      " [  1.00000000e+00   0.00000000e+00   0.00000000e+00   9.19923900e+04\n",
      "    1.35495070e+05   2.52664930e+05]\n",
      " [  0.00000000e+00   1.00000000e+00   0.00000000e+00   1.19943240e+05\n",
      "    1.56547420e+05   2.56512920e+05]\n",
      " [  0.00000000e+00   0.00000000e+00   1.00000000e+00   1.14523610e+05\n",
      "    1.22616840e+05   2.61776230e+05]\n",
      " [  1.00000000e+00   0.00000000e+00   0.00000000e+00   7.80131100e+04\n",
      "    1.21597550e+05   2.64346060e+05]\n",
      " [  0.00000000e+00   0.00000000e+00   1.00000000e+00   9.46571600e+04\n",
      "    1.45077580e+05   2.82574310e+05]\n",
      " [  0.00000000e+00   1.00000000e+00   0.00000000e+00   9.17491600e+04\n",
      "    1.14175790e+05   2.94919570e+05]\n",
      " [  0.00000000e+00   0.00000000e+00   1.00000000e+00   8.64197000e+04\n",
      "    1.53514110e+05   0.00000000e+00]\n",
      " [  1.00000000e+00   0.00000000e+00   0.00000000e+00   7.62538600e+04\n",
      "    1.13867300e+05   2.98664470e+05]\n",
      " [  0.00000000e+00   0.00000000e+00   1.00000000e+00   7.83894700e+04\n",
      "    1.53773430e+05   2.99737290e+05]\n",
      " [  0.00000000e+00   1.00000000e+00   0.00000000e+00   7.39945600e+04\n",
      "    1.22782750e+05   3.03319260e+05]\n",
      " [  0.00000000e+00   1.00000000e+00   0.00000000e+00   6.75325300e+04\n",
      "    1.05751030e+05   3.04768730e+05]\n",
      " [  0.00000000e+00   0.00000000e+00   1.00000000e+00   7.70440100e+04\n",
      "    9.92813400e+04   1.40574810e+05]\n",
      " [  1.00000000e+00   0.00000000e+00   0.00000000e+00   6.46647100e+04\n",
      "    1.39553160e+05   1.37962620e+05]\n",
      " [  0.00000000e+00   1.00000000e+00   0.00000000e+00   7.53288700e+04\n",
      "    1.44135980e+05   1.34050070e+05]\n",
      " [  0.00000000e+00   0.00000000e+00   1.00000000e+00   7.21076000e+04\n",
      "    1.27864550e+05   3.53183810e+05]\n",
      " [  0.00000000e+00   1.00000000e+00   0.00000000e+00   6.60515200e+04\n",
      "    1.82645560e+05   1.18148200e+05]\n",
      " [  0.00000000e+00   0.00000000e+00   1.00000000e+00   6.56054800e+04\n",
      "    1.53032060e+05   1.07138380e+05]\n",
      " [  0.00000000e+00   1.00000000e+00   0.00000000e+00   6.19944800e+04\n",
      "    1.15641280e+05   9.11312400e+04]\n",
      " [  0.00000000e+00   0.00000000e+00   1.00000000e+00   6.11363800e+04\n",
      "    1.52701920e+05   8.82182300e+04]\n",
      " [  1.00000000e+00   0.00000000e+00   0.00000000e+00   6.34088600e+04\n",
      "    1.29219610e+05   4.60852500e+04]\n",
      " [  0.00000000e+00   1.00000000e+00   0.00000000e+00   5.54939500e+04\n",
      "    1.03057490e+05   2.14634810e+05]\n",
      " [  1.00000000e+00   0.00000000e+00   0.00000000e+00   4.64260700e+04\n",
      "    1.57693920e+05   2.10797670e+05]\n",
      " [  0.00000000e+00   0.00000000e+00   1.00000000e+00   4.60140200e+04\n",
      "    8.50474400e+04   2.05517640e+05]\n",
      " [  0.00000000e+00   1.00000000e+00   0.00000000e+00   2.86637600e+04\n",
      "    1.27056210e+05   2.01126820e+05]\n",
      " [  1.00000000e+00   0.00000000e+00   0.00000000e+00   4.40699500e+04\n",
      "    5.12831400e+04   1.97029420e+05]\n",
      " [  0.00000000e+00   0.00000000e+00   1.00000000e+00   2.02295900e+04\n",
      "    6.59479300e+04   1.85265100e+05]\n",
      " [  1.00000000e+00   0.00000000e+00   0.00000000e+00   3.85585100e+04\n",
      "    8.29820900e+04   1.74999300e+05]\n",
      " [  1.00000000e+00   0.00000000e+00   0.00000000e+00   2.87543300e+04\n",
      "    1.18546050e+05   1.72795670e+05]\n",
      " [  0.00000000e+00   1.00000000e+00   0.00000000e+00   2.78929200e+04\n",
      "    8.47107700e+04   1.64470710e+05]\n",
      " [  1.00000000e+00   0.00000000e+00   0.00000000e+00   2.36409300e+04\n",
      "    9.61896300e+04   1.48001110e+05]\n",
      " [  0.00000000e+00   0.00000000e+00   1.00000000e+00   1.55057300e+04\n",
      "    1.27382300e+05   3.55341700e+04]\n",
      " [  1.00000000e+00   0.00000000e+00   0.00000000e+00   2.21777400e+04\n",
      "    1.54806140e+05   2.83347200e+04]\n",
      " [  0.00000000e+00   0.00000000e+00   1.00000000e+00   1.00023000e+03\n",
      "    1.24153040e+05   1.90393000e+03]\n",
      " [  0.00000000e+00   1.00000000e+00   0.00000000e+00   1.31546000e+03\n",
      "    1.15816210e+05   2.97114460e+05]\n",
      " [  1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    1.35426920e+05   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   1.00000000e+00   5.42050000e+02\n",
      "    5.17431500e+04   0.00000000e+00]\n",
      " [  1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    1.16983800e+05   4.51730600e+04]]\n"
     ]
    }
   ],
   "source": [
    "labelencoder_X=LabelEncoder()\n",
    "X[:, 3]=labelencoder_X.fit_transform(X[:, 3])\n",
    "onehotencoder=OneHotEncoder(categorical_features=[3])\n",
    "X=onehotencoder.fit_transform(X).toarray()\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=X[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sharique Ahmed\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now apply linear model\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor=LinearRegression()\n",
    "regressor.fit(X_train, y_train) #fitting the regressor to the training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predicting the test set\n",
    "y_pred=regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 103015.20159796,  132582.27760815,  132447.73845175,\n",
       "         71976.09851258,  178537.48221056,  116161.24230166,\n",
       "         67851.69209676,   98791.73374687,  113969.43533013,\n",
       "        167921.06569551])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred #predicted profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 103282.38,  144259.4 ,  146121.95,   77798.83,  191050.39,\n",
       "        105008.31,   81229.06,   97483.56,  110352.25,  166187.94])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test #real profit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "# The equation of linear regression is y=b0 + b1x1 + b2x2+.... where b0 is the constant\n",
    "# in the above model when we apply linear regression the model automatically adds constant b0 in the equation\n",
    "# something which is not there in the stats model\n",
    "# so we add matrix of 1 in frst column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>131876.90</td>\n",
       "      <td>99814.71</td>\n",
       "      <td>362861.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134615.46</td>\n",
       "      <td>147198.87</td>\n",
       "      <td>127716.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130298.13</td>\n",
       "      <td>145530.06</td>\n",
       "      <td>323876.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120542.52</td>\n",
       "      <td>148718.95</td>\n",
       "      <td>311613.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123334.88</td>\n",
       "      <td>108679.17</td>\n",
       "      <td>304981.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101913.08</td>\n",
       "      <td>110594.11</td>\n",
       "      <td>229160.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100671.96</td>\n",
       "      <td>91790.61</td>\n",
       "      <td>249744.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93863.75</td>\n",
       "      <td>127320.38</td>\n",
       "      <td>249839.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91992.39</td>\n",
       "      <td>135495.07</td>\n",
       "      <td>252664.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119943.24</td>\n",
       "      <td>156547.42</td>\n",
       "      <td>256512.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>114523.61</td>\n",
       "      <td>122616.84</td>\n",
       "      <td>261776.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78013.11</td>\n",
       "      <td>121597.55</td>\n",
       "      <td>264346.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94657.16</td>\n",
       "      <td>145077.58</td>\n",
       "      <td>282574.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91749.16</td>\n",
       "      <td>114175.79</td>\n",
       "      <td>294919.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86419.70</td>\n",
       "      <td>153514.11</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76253.86</td>\n",
       "      <td>113867.30</td>\n",
       "      <td>298664.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78389.47</td>\n",
       "      <td>153773.43</td>\n",
       "      <td>299737.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73994.56</td>\n",
       "      <td>122782.75</td>\n",
       "      <td>303319.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67532.53</td>\n",
       "      <td>105751.03</td>\n",
       "      <td>304768.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77044.01</td>\n",
       "      <td>99281.34</td>\n",
       "      <td>140574.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64664.71</td>\n",
       "      <td>139553.16</td>\n",
       "      <td>137962.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75328.87</td>\n",
       "      <td>144135.98</td>\n",
       "      <td>134050.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72107.60</td>\n",
       "      <td>127864.55</td>\n",
       "      <td>353183.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66051.52</td>\n",
       "      <td>182645.56</td>\n",
       "      <td>118148.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65605.48</td>\n",
       "      <td>153032.06</td>\n",
       "      <td>107138.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61994.48</td>\n",
       "      <td>115641.28</td>\n",
       "      <td>91131.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61136.38</td>\n",
       "      <td>152701.92</td>\n",
       "      <td>88218.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63408.86</td>\n",
       "      <td>129219.61</td>\n",
       "      <td>46085.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55493.95</td>\n",
       "      <td>103057.49</td>\n",
       "      <td>214634.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46426.07</td>\n",
       "      <td>157693.92</td>\n",
       "      <td>210797.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46014.02</td>\n",
       "      <td>85047.44</td>\n",
       "      <td>205517.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28663.76</td>\n",
       "      <td>127056.21</td>\n",
       "      <td>201126.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44069.95</td>\n",
       "      <td>51283.14</td>\n",
       "      <td>197029.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20229.59</td>\n",
       "      <td>65947.93</td>\n",
       "      <td>185265.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38558.51</td>\n",
       "      <td>82982.09</td>\n",
       "      <td>174999.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28754.33</td>\n",
       "      <td>118546.05</td>\n",
       "      <td>172795.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27892.92</td>\n",
       "      <td>84710.77</td>\n",
       "      <td>164470.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23640.93</td>\n",
       "      <td>96189.63</td>\n",
       "      <td>148001.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15505.73</td>\n",
       "      <td>127382.30</td>\n",
       "      <td>35534.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22177.74</td>\n",
       "      <td>154806.14</td>\n",
       "      <td>28334.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1000.23</td>\n",
       "      <td>124153.04</td>\n",
       "      <td>1903.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1315.46</td>\n",
       "      <td>115816.21</td>\n",
       "      <td>297114.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>135426.92</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>542.05</td>\n",
       "      <td>51743.15</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>116983.80</td>\n",
       "      <td>45173.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2          3          4          5\n",
       "0   1.0  0.0  1.0  165349.20  136897.80  471784.10\n",
       "1   1.0  0.0  0.0  162597.70  151377.59  443898.53\n",
       "2   1.0  1.0  0.0  153441.51  101145.55  407934.54\n",
       "3   1.0  0.0  1.0  144372.41  118671.85  383199.62\n",
       "4   1.0  1.0  0.0  142107.34   91391.77  366168.42\n",
       "5   1.0  0.0  1.0  131876.90   99814.71  362861.36\n",
       "6   1.0  0.0  0.0  134615.46  147198.87  127716.82\n",
       "7   1.0  1.0  0.0  130298.13  145530.06  323876.68\n",
       "8   1.0  0.0  1.0  120542.52  148718.95  311613.29\n",
       "9   1.0  0.0  0.0  123334.88  108679.17  304981.62\n",
       "10  1.0  1.0  0.0  101913.08  110594.11  229160.95\n",
       "11  1.0  0.0  0.0  100671.96   91790.61  249744.55\n",
       "12  1.0  1.0  0.0   93863.75  127320.38  249839.44\n",
       "13  1.0  0.0  0.0   91992.39  135495.07  252664.93\n",
       "14  1.0  1.0  0.0  119943.24  156547.42  256512.92\n",
       "15  1.0  0.0  1.0  114523.61  122616.84  261776.23\n",
       "16  1.0  0.0  0.0   78013.11  121597.55  264346.06\n",
       "17  1.0  0.0  1.0   94657.16  145077.58  282574.31\n",
       "18  1.0  1.0  0.0   91749.16  114175.79  294919.57\n",
       "19  1.0  0.0  1.0   86419.70  153514.11       0.00\n",
       "20  1.0  0.0  0.0   76253.86  113867.30  298664.47\n",
       "21  1.0  0.0  1.0   78389.47  153773.43  299737.29\n",
       "22  1.0  1.0  0.0   73994.56  122782.75  303319.26\n",
       "23  1.0  1.0  0.0   67532.53  105751.03  304768.73\n",
       "24  1.0  0.0  1.0   77044.01   99281.34  140574.81\n",
       "25  1.0  0.0  0.0   64664.71  139553.16  137962.62\n",
       "26  1.0  1.0  0.0   75328.87  144135.98  134050.07\n",
       "27  1.0  0.0  1.0   72107.60  127864.55  353183.81\n",
       "28  1.0  1.0  0.0   66051.52  182645.56  118148.20\n",
       "29  1.0  0.0  1.0   65605.48  153032.06  107138.38\n",
       "30  1.0  1.0  0.0   61994.48  115641.28   91131.24\n",
       "31  1.0  0.0  1.0   61136.38  152701.92   88218.23\n",
       "32  1.0  0.0  0.0   63408.86  129219.61   46085.25\n",
       "33  1.0  1.0  0.0   55493.95  103057.49  214634.81\n",
       "34  1.0  0.0  0.0   46426.07  157693.92  210797.67\n",
       "35  1.0  0.0  1.0   46014.02   85047.44  205517.64\n",
       "36  1.0  1.0  0.0   28663.76  127056.21  201126.82\n",
       "37  1.0  0.0  0.0   44069.95   51283.14  197029.42\n",
       "38  1.0  0.0  1.0   20229.59   65947.93  185265.10\n",
       "39  1.0  0.0  0.0   38558.51   82982.09  174999.30\n",
       "40  1.0  0.0  0.0   28754.33  118546.05  172795.67\n",
       "41  1.0  1.0  0.0   27892.92   84710.77  164470.71\n",
       "42  1.0  0.0  0.0   23640.93   96189.63  148001.11\n",
       "43  1.0  0.0  1.0   15505.73  127382.30   35534.17\n",
       "44  1.0  0.0  0.0   22177.74  154806.14   28334.72\n",
       "45  1.0  0.0  1.0    1000.23  124153.04    1903.93\n",
       "46  1.0  1.0  0.0    1315.46  115816.21  297114.46\n",
       "47  1.0  0.0  0.0       0.00  135426.92       0.00\n",
       "48  1.0  0.0  1.0     542.05   51743.15       0.00\n",
       "49  1.0  0.0  0.0       0.00  116983.80   45173.06"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X=np.append(arr=X, values=np.ones((50,1)).astype(int), axis=1) #50 rows that is the dimension of X and 1 column\n",
    "#but in the line above we are adding one matrix at the end of X but we want to add it at first\n",
    "X=np.append(arr=np.ones((50,1)).astype(int), values=X, axis=1)\n",
    "pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now we will test and store only those variables that are statistically significant and we will store the value in table X optimal\n",
    "X_opt=X[:, [0,1,2,3,4,5]]\n",
    "#Step 2 Fit the full model with all possible predictors\n",
    "regressor_OLS=sm.OLS(endog=y, exog=X_opt).fit() #endog is for deoendent variable and exog is the independent variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.951\n",
      "Model:                            OLS   Adj. R-squared:                  0.945\n",
      "Method:                 Least Squares   F-statistic:                     169.9\n",
      "Date:                Sat, 26 May 2018   Prob (F-statistic):           1.34e-27\n",
      "Time:                        18:38:32   Log-Likelihood:                -525.38\n",
      "No. Observations:                  50   AIC:                             1063.\n",
      "Df Residuals:                      44   BIC:                             1074.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       5.013e+04   6884.820      7.281      0.000    3.62e+04     6.4e+04\n",
      "x1           198.7888   3371.007      0.059      0.953   -6595.030    6992.607\n",
      "x2           -41.8870   3256.039     -0.013      0.990   -6604.003    6520.229\n",
      "x3             0.8060      0.046     17.369      0.000       0.712       0.900\n",
      "x4            -0.0270      0.052     -0.517      0.608      -0.132       0.078\n",
      "x5             0.0270      0.017      1.574      0.123      -0.008       0.062\n",
      "==============================================================================\n",
      "Omnibus:                       14.782   Durbin-Watson:                   1.283\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.266\n",
      "Skew:                          -0.948   Prob(JB):                     2.41e-05\n",
      "Kurtosis:                       5.572   Cond. No.                     1.45e+06\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.45e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "#Step 3\n",
    "print(regressor_OLS.summary()) #here we are checking for least significant variable and as we can see\n",
    "#variable with index 2 has the highest p value so we first remove that index\n",
    "#we now proceed to step 4 to remove that variable and then repeat the operation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.951\n",
      "Model:                            OLS   Adj. R-squared:                  0.946\n",
      "Method:                 Least Squares   F-statistic:                     217.2\n",
      "Date:                Sat, 26 May 2018   Prob (F-statistic):           8.49e-29\n",
      "Time:                        18:38:32   Log-Likelihood:                -525.38\n",
      "No. Observations:                  50   AIC:                             1061.\n",
      "Df Residuals:                      45   BIC:                             1070.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       5.011e+04   6647.870      7.537      0.000    3.67e+04    6.35e+04\n",
      "x1           220.1585   2900.536      0.076      0.940   -5621.821    6062.138\n",
      "x2             0.8060      0.046     17.606      0.000       0.714       0.898\n",
      "x3            -0.0270      0.052     -0.523      0.604      -0.131       0.077\n",
      "x4             0.0270      0.017      1.592      0.118      -0.007       0.061\n",
      "==============================================================================\n",
      "Omnibus:                       14.758   Durbin-Watson:                   1.282\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.172\n",
      "Skew:                          -0.948   Prob(JB):                     2.53e-05\n",
      "Kurtosis:                       5.563   Cond. No.                     1.40e+06\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.4e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "X_opt=X[:, [0,1,3,4,5]]\n",
    "regressor_OLS=sm.OLS(endog=y, exog=X_opt).fit()\n",
    "print(regressor_OLS.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.951\n",
      "Model:                            OLS   Adj. R-squared:                  0.948\n",
      "Method:                 Least Squares   F-statistic:                     296.0\n",
      "Date:                Sat, 26 May 2018   Prob (F-statistic):           4.53e-30\n",
      "Time:                        18:38:33   Log-Likelihood:                -525.39\n",
      "No. Observations:                  50   AIC:                             1059.\n",
      "Df Residuals:                      46   BIC:                             1066.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       5.012e+04   6572.353      7.626      0.000    3.69e+04    6.34e+04\n",
      "x1             0.8057      0.045     17.846      0.000       0.715       0.897\n",
      "x2            -0.0268      0.051     -0.526      0.602      -0.130       0.076\n",
      "x3             0.0272      0.016      1.655      0.105      -0.006       0.060\n",
      "==============================================================================\n",
      "Omnibus:                       14.838   Durbin-Watson:                   1.282\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.442\n",
      "Skew:                          -0.949   Prob(JB):                     2.21e-05\n",
      "Kurtosis:                       5.586   Cond. No.                     1.40e+06\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.4e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "X_opt=X[:, [0,3,4,5]]\n",
    "regressor_OLS=sm.OLS(endog=y, exog=X_opt).fit()\n",
    "print(regressor_OLS.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.950\n",
      "Model:                            OLS   Adj. R-squared:                  0.948\n",
      "Method:                 Least Squares   F-statistic:                     450.8\n",
      "Date:                Sat, 26 May 2018   Prob (F-statistic):           2.16e-31\n",
      "Time:                        18:38:33   Log-Likelihood:                -525.54\n",
      "No. Observations:                  50   AIC:                             1057.\n",
      "Df Residuals:                      47   BIC:                             1063.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       4.698e+04   2689.933     17.464      0.000    4.16e+04    5.24e+04\n",
      "x1             0.7966      0.041     19.266      0.000       0.713       0.880\n",
      "x2             0.0299      0.016      1.927      0.060      -0.001       0.061\n",
      "==============================================================================\n",
      "Omnibus:                       14.677   Durbin-Watson:                   1.257\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.161\n",
      "Skew:                          -0.939   Prob(JB):                     2.54e-05\n",
      "Kurtosis:                       5.575   Cond. No.                     5.32e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.32e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "X_opt=X[:, [0,3,5]]\n",
    "regressor_OLS=sm.OLS(endog=y, exog=X_opt).fit()\n",
    "print(regressor_OLS.summary())\n",
    "#here we see that the highest p value of 6% so we will nw remove this indepenent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.947\n",
      "Model:                            OLS   Adj. R-squared:                  0.945\n",
      "Method:                 Least Squares   F-statistic:                     849.8\n",
      "Date:                Sat, 26 May 2018   Prob (F-statistic):           3.50e-32\n",
      "Time:                        18:40:46   Log-Likelihood:                -527.44\n",
      "No. Observations:                  50   AIC:                             1059.\n",
      "Df Residuals:                      48   BIC:                             1063.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       4.903e+04   2537.897     19.320      0.000    4.39e+04    5.41e+04\n",
      "x1             0.8543      0.029     29.151      0.000       0.795       0.913\n",
      "==============================================================================\n",
      "Omnibus:                       13.727   Durbin-Watson:                   1.116\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               18.536\n",
      "Skew:                          -0.911   Prob(JB):                     9.44e-05\n",
      "Kurtosis:                       5.361   Cond. No.                     1.65e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.65e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "X_opt=X[:, [0,3]]\n",
    "regressor_OLS=sm.OLS(endog=y, exog=X_opt).fit()\n",
    "print(regressor_OLS.summary())\n",
    "#only one independent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So R and D spend is the only independent variable is a strong predictor of the profit, the independent variable that can\n",
    "statistically predict the high significance of profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
